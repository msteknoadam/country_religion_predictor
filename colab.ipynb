{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "outputs": [],
      "source": [
        "I'm making this project with TensorFlow 2.0 so I need to specify that for Google Colab since it should be compatible with Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q seaborn\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UnootnQ2w3BV"
      },
      "outputs": [],
      "source": [
        "Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Here, we are downloading the flags dataset from UCI's archive and then we turn it into Pandas DataFrame so we can use it on our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/flags/flag.data'\n",
        "\n",
        "dataset_path = tf.keras.utils.get_file(\"train.csv\", data_url)\n",
        "\n",
        "column_names = ['Name','Landmass','Zone','Area','Population', 'Language', \n",
        "                'Religion', 'Bars', 'Stripes', 'Colours', 'Red', 'Green', \n",
        "                'Blue', 'Gold', 'White', 'Black', 'Orange', 'Main Hue',\n",
        "                'Circles', 'Crosses', 'Saltires', 'Quarters', 'Sunstars',\n",
        "                'Crescent', 'Triangle', 'Icon', 'Animate', 'Text', 'Top Left',\n",
        "                'Bottom Right']\n",
        "\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"Unknown\", sep=\",\")\n",
        "\n",
        "raw_dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "We need to drop some values such as country names, landmass etc. since I believe they don't have any relationship with religion of a country.\n",
        "I also choose to drop very spesific things & things that may cause misleading things (For example, green colour might be often to seen in let's say a Muslim country flag but asking for every colour wouldn't be great in my opinion because this project is kind of prediction game as you can see at the end of the codes.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = raw_dataset.copy()\n",
        "\n",
        "dataset = dataset.drop(['Name', 'Area', 'Landmass', 'Population', 'Bars', \n",
        "                        'Red', 'Green', 'Blue', 'Gold', \n",
        "                        'White', 'Black', 'Orange', 'Main Hue', 'Circles', 'Crosses', \n",
        "                        'Saltires', 'Quarters', 'Crescent', 'Triangle', \n",
        "                        'Top Left', 'Bottom Right'], axis = 1)\n",
        "\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "At this step, we prepare our training dataset. We need to drop religion column from training dataset because model needs to find a correlation between the other parameters & religion of a country. If we leave religion column inside the training dataset, it will probably cause our model to not to actually find any correlations because it will think like \"Whenever the religion is x, the output should be x\" since that will be the case while fitting the model, which is a thing we should be avoiding if we want a model that can ACTUALLY predict instead of just cheating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = dataset\n",
        "train_dataset = train_dataset.drop('Religion', axis = 1)\n",
        "\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "\n",
        "train_labels = dataset['Religion']\n",
        "train_dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "There is a halt callback because this model generally reaches up to 90% accuracy so there is no need to wait until all 2500 epochs finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "class haltCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy') >= 0.90):\n",
        "            print(\"\\n\\n\\nReached 90% accuracy so cancelling training!\\n\\n\\n\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "\n",
        "modelHaltCallback = haltCallback()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "We are building the model here. I have chosen to use Sparse Categorical Crossentropy since we have 8 different categories of religions (You can refer to them from the flag.names file in this repository. The whole dataset explaining is written in that file which is taken from UCI's archive.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    layers.Dense(128, input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(train_dataset), activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', \n",
        "                metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Now, it's time to fit the model so we can use that model to predict on some values later on. We're defining a history variable while fitting so we can later use that history logs to create some graphs about our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, train_labels, epochs=2500, validation_split = 0.2, callbacks=[tfdocs.modeling.EpochDots(), modelHaltCallback])"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "As the fitting is over now, we can see the correlation between Sparse Categorical Crossentropy & Model Accuracy on a graph. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "# print(hist.tail())\n",
        "\n",
        "def mapRange(valueToBeRanged, currentMin, currentMax, newMin, newMax):\n",
        "    return ((valueToBeRanged) / (currentMax - currentMin) * (newMax - newMin))\n",
        "\n",
        "plt.plot(hist['epoch'], mapRange(hist['sparse_categorical_crossentropy'], 0, hist['sparse_categorical_crossentropy'].max(), 0, 100), 'b', label='Sparse Categorical Crossentropy')\n",
        "plt.plot(hist['epoch'], mapRange(hist['accuracy'], 0, 1, 0, 100), 'g', label='Training loss')\n",
        "plt.title('Correlation between Sparse Categorical Crossentropy & Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "outputs": [],
      "source": [
        "And now it's the final time! I actually thought about making this project like a game so any user could just download this and then enter their own values from the GUI itself but since it's not something possible on Google Colab as far as I know, I entered the values of Peru from the dataset and luckily, our model predicted it correctly!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "religion_dict = ['Catholic', 'Other Christian', 'Muslim', 'Buddhist', 'Hindu', 'Ethnic', 'Marxist', 'Others']\n",
        "print(\"Now, it's time to predict!\")\n",
        "# predZone = input(\"In which geographic quadrant (based on Greenwich and the Equator) is that country? (Enter 1 for North-East, 2 for South-East, 3 for South-West and 4 for North-West)\")\n",
        "# predLang = input(\"What language is being spoken in that country? (1=English, 2=Spanish, 3=French, 4=German, 5=Slavic, 6=Other Indo-European, 7=Chinese, 8=Arabic, 9=Japanese/Turkish/Finnish/Magyar, 10=Others)\")\n",
        "# predStripes = input(\"How many stripes are there in that country's flag?\")\n",
        "# predColours = input(\"How many DIFFERENT colours are there in that country's flag?\")\n",
        "# predSunStars = input(\"How many suns or stars are there in that country's flag?\")\n",
        "# predIcon = input(\"Are there any kind of inanimate images (e.g., a boat) on that country's flag? (Type 1 for yes, 0 for no)\")\n",
        "# predAnimate = input(\"Are there any kind of animate images (e.g., an eagle, a tree, a human hand) on that country's flag? (Type 1 for yes, 0 for no)\")\n",
        "# predText = input(\"Are there any letters or writing on the flag (e.g., a motto or slogan) on that country's flag? (Type 1 for yes, 0 for no)\")\n",
        "\n",
        "\n",
        "predZone = 3\n",
        "predLang = 2\n",
        "predStripes = 0\n",
        "predColours = 2\n",
        "predSunStars = 0\n",
        "predIcon = 0\n",
        "predAnimate = 0\n",
        "predText = 0\n",
        "predData = pd.DataFrame([[predZone, predLang, predStripes, predColours, predSunStars, predIcon, predAnimate, predText]], ['Zone', 'Language', 'Stripes', 'Colours', 'Sunstars', 'Icon', 'Animate', 'Text'])\n",
        "prediction = model.predict(predData)\n",
        "print(f\"Model predicts that country's religion is: {religion_dict[np.argmax(prediction)]}.\")\n",
        "print(f\"Based on this, that country might be one of these: {', '.join(raw_dataset['Name'].loc[raw_dataset['Religion'] == np.argmax(prediction)])}\") #PERU"
      ]
    }
  ]
}