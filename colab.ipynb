{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python37364bit7bb37f67a6254547b7b5cd98da0c4f82",
      "display_name": "Python 3.7.3 64-bit"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "I'm making this project with TensorFlow 2.0 so I need to specify that for Google Colab since it should be compatible with Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q seaborn\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "!pip install -U tensorboard >piplog 2>&1\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "UnootnQ2w3BV"
      },
      "outputs": [],
      "source": [
        "Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Here, we are downloading the flags dataset from UCI's archive and then we turn it into Pandas DataFrame so we can use it on our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Landmass</th>\n      <th>Zone</th>\n      <th>Area</th>\n      <th>Population</th>\n      <th>Language</th>\n      <th>Religion</th>\n      <th>Bars</th>\n      <th>Stripes</th>\n      <th>Colours</th>\n      <th>...</th>\n      <th>Saltires</th>\n      <th>Quarters</th>\n      <th>Sunstars</th>\n      <th>Crescent</th>\n      <th>Triangle</th>\n      <th>Icon</th>\n      <th>Animate</th>\n      <th>Text</th>\n      <th>Top Left</th>\n      <th>Bottom Right</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>189</th>\n      <td>Western-Samoa</td>\n      <td>6</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>blue</td>\n      <td>red</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>Yugoslavia</td>\n      <td>3</td>\n      <td>1</td>\n      <td>256</td>\n      <td>22</td>\n      <td>6</td>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>blue</td>\n      <td>red</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>Zaire</td>\n      <td>4</td>\n      <td>2</td>\n      <td>905</td>\n      <td>28</td>\n      <td>10</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>green</td>\n      <td>green</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>Zambia</td>\n      <td>4</td>\n      <td>2</td>\n      <td>753</td>\n      <td>6</td>\n      <td>10</td>\n      <td>5</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>green</td>\n      <td>brown</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>Zimbabwe</td>\n      <td>4</td>\n      <td>2</td>\n      <td>391</td>\n      <td>8</td>\n      <td>10</td>\n      <td>5</td>\n      <td>0</td>\n      <td>7</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>green</td>\n      <td>green</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 30 columns</p>\n</div>",
            "text/plain": "              Name  Landmass  Zone  Area  Population  Language  Religion  \\\n189  Western-Samoa         6     3     3           0         1         1   \n190     Yugoslavia         3     1   256          22         6         6   \n191          Zaire         4     2   905          28        10         5   \n192         Zambia         4     2   753           6        10         5   \n193       Zimbabwe         4     2   391           8        10         5   \n\n     Bars  Stripes  Colours  ...  Saltires  Quarters  Sunstars  Crescent  \\\n189     0        0        3  ...         0         1         5         0   \n190     0        3        4  ...         0         0         1         0   \n191     0        0        4  ...         0         0         0         0   \n192     3        0        4  ...         0         0         0         0   \n193     0        7        5  ...         0         0         1         0   \n\n     Triangle  Icon  Animate Text  Top Left  Bottom Right  \n189         0     0        0    0      blue           red  \n190         0     0        0    0      blue           red  \n191         0     1        1    0     green         green  \n192         0     0        1    0     green         brown  \n193         1     1        1    0     green         green  \n\n[5 rows x 30 columns]"
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/flags/flag.data'\n",
        "\n",
        "dataset_path = tf.keras.utils.get_file(\"train.csv\", data_url)\n",
        "\n",
        "column_names = ['Name','Landmass','Zone','Area','Population', 'Language', \n",
        "                'Religion', 'Bars', 'Stripes', 'Colours', 'Red', 'Green', \n",
        "                'Blue', 'Gold', 'White', 'Black', 'Orange', 'Main Hue',\n",
        "                'Circles', 'Crosses', 'Saltires', 'Quarters', 'Sunstars',\n",
        "                'Crescent', 'Triangle', 'Icon', 'Animate', 'Text', 'Top Left',\n",
        "                'Bottom Right']\n",
        "\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"Unknown\", sep=\",\")\n",
        "\n",
        "raw_dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "We need to drop some values such as country names, landmass etc. since I believe they don't have any relationship with religion of a country.\n",
        "I also choose to drop very spesific things & things that may cause misleading things (For example, green colour might be often to seen in let's say a Muslim country flag but asking for every colour wouldn't be great in my opinion because this project is kind of prediction game as you can see at the end of the codes.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Zone</th>\n      <th>Language</th>\n      <th>Religion</th>\n      <th>Stripes</th>\n      <th>Colours</th>\n      <th>Sunstars</th>\n      <th>Icon</th>\n      <th>Animate</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>189</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>1</td>\n      <td>6</td>\n      <td>6</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "     Zone  Language  Religion  Stripes  Colours  Sunstars  Icon  Animate  Text\n189     3         1         1        0        3         5     0        0     0\n190     1         6         6        3        4         1     0        0     0\n191     2        10         5        0        4         0     1        1     0\n192     2        10         5        0        4         0     0        1     0\n193     2        10         5        7        5         1     1        1     0"
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = raw_dataset.copy()\n",
        "\n",
        "dataset = dataset.drop(['Name', 'Area', 'Landmass', 'Population', 'Bars', \n",
        "                        'Red', 'Green', 'Blue', 'Gold', \n",
        "                        'White', 'Black', 'Orange', 'Main Hue', 'Circles', 'Crosses', \n",
        "                        'Saltires', 'Quarters', 'Crescent', 'Triangle', \n",
        "                        'Top Left', 'Bottom Right'], axis = 1)\n",
        "\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "At this step, we prepare our training dataset. We need to drop religion column from training dataset because model needs to find a correlation between the other parameters & religion of a country. If we leave religion column inside the training dataset, it will probably cause our model to not to actually find any correlations because it will think like \"Whenever the religion is x, the output should be x\" since that will be the case while fitting the model, which is a thing we should be avoiding if we want a model that can ACTUALLY predict instead of just cheating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Zone</th>\n      <th>Language</th>\n      <th>Stripes</th>\n      <th>Colours</th>\n      <th>Sunstars</th>\n      <th>Icon</th>\n      <th>Animate</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>189</th>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>2</td>\n      <td>10</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>2</td>\n      <td>10</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>2</td>\n      <td>10</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "     Zone  Language  Stripes  Colours  Sunstars  Icon  Animate  Text\n189     3         1        0        3         5     0        0     0\n190     1         6        3        4         1     0        0     0\n191     2        10        0        4         0     1        1     0\n192     2        10        0        4         0     0        1     0\n193     2        10        7        5         1     1        1     0"
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = dataset\n",
        "train_dataset = train_dataset.drop('Religion', axis = 1)\n",
        "\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "\n",
        "train_labels = dataset['Religion']\n",
        "train_dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "There is a halt callback because this model generally reaches up to 90% accuracy so there is no need to wait until all 2500 epochs finish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class haltCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy') >= 0.90):\n",
        "            print(\"\\n\\n\\nReached 90% accuracy so cancelling training!\\n\\n\\n\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "\n",
        "modelHaltCallback = haltCallback()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "We are building the model here. I have chosen to use Sparse Categorical Crossentropy since we have 8 different categories of religions (You can refer to them from the flag.names file in this repository. The whole dataset explaining is written in that file which is taken from UCI's archive.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "WARNING: Logging before flag parsing goes to stderr.\nW0108 21:59:22.263863 18840 deprecation.py:506] From C:\\Users\\TEKNO\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 128)               1152      \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_2 (Dense)              (None, 194)               25026     \n=================================================================\nTotal params: 42,690\nTrainable params: 42,690\nNon-trainable params: 0\n_________________________________________________________________\n"
        }
      ],
      "source": [
        "def build_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    layers.Dense(128, input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(train_dataset), activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', \n",
        "                metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "We need to specify our logs dir so we can store our data and then upload them to TensorBoard later on. We also need to create a callback for TensorBoard because we need to store our logs in a way that TensorBoard can directly upload it by itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_dir=\"logs\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Now, it's time to fit the model so we can use that model to predict on some values later on. We're defining a history variable while fitting so we can later use that history logs to create some graphs about our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Train on 155 samples, validate on 39 samples\nEpoch 1/2500\n 32/155 [=====>........................] - ETA: 0s - loss: 5.5037 - acc: 0.0000e+00 - sparse_categorical_crossentropy: 5.5037\nEpoch: 0, acc:0.0323,  loss:5.1830,  sparse_categorical_crossentropy:5.1830,  val_acc:0.3333,  val_loss:4.1589,  val_sparse_categorical_crossentropy:4.1589,  \n."
        },
        {
          "ename": "TypeError",
          "evalue": "'>=' not supported between instances of 'NoneType' and 'float'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-8-8bce130361a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtfdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEpochDots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelHaltCallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m       \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m     \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-5-8ab2d4b75733>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mhaltCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\\n\\nReached 90% accuracy so cancelling training!\\n\\n\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'NoneType' and 'float'"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_dataset, train_labels, epochs=2500, validation_split = 0.2, callbacks=[tfdocs.modeling.EpochDots(), modelHaltCallback, tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "As the fitting is over now, we can see the correlation between Sparse Categorical Crossentropy & Model Accuracy on a graph. (We will be able to see all of these graphs interactively when we upload our fitting history to TensorBoard at the end of this project.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "# print(hist.tail())\n",
        "\n",
        "def mapRange(valueToBeRanged, currentMin, currentMax, newMin, newMax):\n",
        "    return ((valueToBeRanged) / (currentMax - currentMin) * (newMax - newMin))\n",
        "\n",
        "plt.plot(hist['epoch'], mapRange(hist['sparse_categorical_crossentropy'], 0, hist['sparse_categorical_crossentropy'].max(), 0, 100), 'b', label='Sparse Categorical Crossentropy')\n",
        "plt.plot(hist['epoch'], mapRange(hist['accuracy'], 0, 1, 0, 100), 'g', label='Model Accuracy')\n",
        "plt.title('Correlation between Sparse Categorical Crossentropy & Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "And now it's the final time! I actually thought about making this project like a game so any user could just download this and then enter their own values from the GUI itself but since it's not something possible on Google Colab as far as I know, I entered the values of Peru from the dataset and luckily, our model predicted it correctly!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "religion_dict = ['Catholic', 'Other Christian', 'Muslim', 'Buddhist', 'Hindu', 'Ethnic', 'Marxist', 'Others']\n",
        "print(\"Now, it's time to predict!\")\n",
        "# predZone = input(\"In which geographic quadrant (based on Greenwich and the Equator) is that country? (Enter 1 for North-East, 2 for South-East, 3 for South-West and 4 for North-West)\")\n",
        "# predLang = input(\"What language is being spoken in that country? (1=English, 2=Spanish, 3=French, 4=German, 5=Slavic, 6=Other Indo-European, 7=Chinese, 8=Arabic, 9=Japanese/Turkish/Finnish/Magyar, 10=Others)\")\n",
        "# predStripes = input(\"How many stripes are there in that country's flag?\")\n",
        "# predColours = input(\"How many DIFFERENT colours are there in that country's flag?\")\n",
        "# predSunStars = input(\"How many suns or stars are there in that country's flag?\")\n",
        "# predIcon = input(\"Are there any kind of inanimate images (e.g., a boat) on that country's flag? (Type 1 for yes, 0 for no)\")\n",
        "# predAnimate = input(\"Are there any kind of animate images (e.g., an eagle, a tree, a human hand) on that country's flag? (Type 1 for yes, 0 for no)\")\n",
        "# predText = input(\"Are there any letters or writing on the flag (e.g., a motto or slogan) on that country's flag? (Type 1 for yes, 0 for no)\")\n",
        "\n",
        "\n",
        "predZone = 3\n",
        "predLang = 2\n",
        "predStripes = 0\n",
        "predColours = 2\n",
        "predSunStars = 0\n",
        "predIcon = 0\n",
        "predAnimate = 0\n",
        "predText = 0\n",
        "predData = pd.DataFrame([[predZone, predLang, predStripes, predColours, predSunStars, predIcon, predAnimate, predText]], ['Zone', 'Language', 'Stripes', 'Colours', 'Sunstars', 'Icon', 'Animate', 'Text'])\n",
        "prediction = model.predict(predData)\n",
        "print(f\"Model predicts that country's religion is: {religion_dict[np.argmax(prediction)]}.\")\n",
        "print(f\"Based on this, that country might be one of these: {', '.join(raw_dataset['Name'].loc[raw_dataset['Religion'] == np.argmax(prediction)])}\") #PERU"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Optionally, I will also save my model to a file so I can use it in browsers using TensorFlow.js library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('trained_model.h5')\n",
        "tf.saved_model.save(model, 'saved_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "After the final, it's time that we upload everything we did to TensorBoard so we can have pretty cool interactive graphs about our model instead of just 1 static image which we created earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tensorboard dev upload --logdir ./logs"
      ]
    }
  ]
}